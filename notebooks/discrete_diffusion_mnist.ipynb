{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7d757",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import model.discrete_diffusers as discrete_diffusers\n",
    "import model.generate as generate\n",
    "import model.image_unet as image_unet\n",
    "from plot.plot import plot_mnist_digits\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tqdm.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2197d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2562da",
   "metadata": {},
   "source": [
    "### Create the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3859c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_tensor = torchvision.transforms.ToTensor()\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    \"/gstore/data/resbioai/tsenga5/datasets\", train=True, transform=(lambda x: torch.round(image_to_tensor(x)))\n",
    ")\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "input_shape = next(iter(data_loader))[0].shape[1:] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7af375",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a01234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the diffuser and model\n",
    "diffuser = discrete_diffusers.BernoulliDiffuser(6, 8, input_shape)\n",
    "\n",
    "t_limit = 50\n",
    "\n",
    "model = image_unet.MNISTProbUNetTimeAdd(t_limit).to(DEVICE)\n",
    "\n",
    "os.environ[\"MODEL_DIR\"] = \"/gstore/data/resbioai/tsenga5/discrete_graph_diffusion/models/trained_models/mnist\"\n",
    "\n",
    "import model.train_model as train_model  # Import this AFTER setting environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcbff50",
   "metadata": {},
   "source": [
    "### Show the forward-diffusion process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1206b06b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " # Show some images after running the diffuser forward for different times\n",
    "time_steps = 5\n",
    "\n",
    "x0, _ = next(iter(data_loader))\n",
    "x0 = x0.cpu().numpy()\n",
    "\n",
    "plot_mnist_digits(x0, grid_size=(10, 1), title=\"t = 0\")\n",
    "x0 = torch.tensor(x0).to(DEVICE)\n",
    "for t in np.arange(1, t_limit + 1, t_limit // time_steps):\n",
    "    xt, _ = diffuser.forward(x0, torch.full(x0.shape[:1], t).to(DEVICE))\n",
    "    plot_mnist_digits(xt.cpu().numpy(), grid_size=(10, 1), title=(\"t = %d\" % t))\n",
    "    \n",
    "# Show the transformation of the distribution of data to the prior distribution\n",
    "time_steps = 30\n",
    "\n",
    "all_t = np.arange(1, t_limit, t_limit // time_steps)\n",
    "all_xt = np.empty((len(all_t),) + x0.shape)\n",
    "for t_i, t in enumerate(all_t):\n",
    "    xt, _ = diffuser.forward(x0, torch.ones(len(x0)).to(DEVICE) * t)\n",
    "    all_xt[t_i] = xt.cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "cmap = plt.get_cmap(\"magma\")\n",
    "for t_i in range(len(all_t)):\n",
    "    ax.hist(np.ravel(all_xt[t_i]), bins=60, histtype=\"step\", color=cmap(t_i / len(all_t)), alpha=0.5, density=True)\n",
    "prior = diffuser.sample_prior(len(x0), torch.ones(len(x0)).to(DEVICE) * t).cpu().numpy()\n",
    "ax.hist(np.ravel(prior), bins=60, histtype=\"step\", color=\"blue\", linewidth=2, density=True, label=\"Sampled prior\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"p(x)\")\n",
    "ax.set_title(\"Evolution of p(x) over forward diffusion\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check progression of posterior probability\n",
    "t_vals = np.arange(1, t_limit)\n",
    "x0, _ = next(iter(data_loader))\n",
    "posterior_probs = np.empty((len(t_vals), *x0.shape))\n",
    "x0 = x0.to(DEVICE)\n",
    "t_0 = torch.zeros(x0.shape[0], device=DEVICE)\n",
    "for i, t in tqdm.notebook.tqdm(enumerate(t_vals), total=len(t_vals)):\n",
    "    t_tens = torch.ones(x0.shape[0], device=DEVICE) * t\n",
    "    xt, p = diffuser.forward(x0, torch.full(x0.shape[:1], t).to(DEVICE))\n",
    "    posterior_probs[i] = p.cpu().numpy()\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "posterior_probs_flattened = posterior_probs.reshape(posterior_probs.shape[0], -1)\n",
    "times = np.tile(t_vals[:, None], (1, posterior_probs_flattened.shape[1]))\n",
    "cmap = plt.get_cmap(\"magma\")\n",
    "bins = np.linspace(0, 1, 60)\n",
    "for t_i in range(len(t_vals)):\n",
    "    ax.hist(posterior_probs_flattened[t_i], bins=bins, histtype=\"step\", color=cmap(t_i / len(t_vals)), alpha=0.5)\n",
    "ax.set_xlabel(\"Posterior probability q(x_{t-1} | x_{t}, x_{0})\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Evolution of posterior probability over time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30da2953",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676bccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.train_ex.run(\n",
    "    \"train_model\",\n",
    "    config_updates={\n",
    "        \"model\": model,\n",
    "        \"diffuser\": diffuser,\n",
    "        \"data_loader\": data_loader,\n",
    "        \"num_epochs\": 10,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"t_limit\": t_limit\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f2be4",
   "metadata": {},
   "source": [
    "### Show generated digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the trained model and go backwards to sample some digits\n",
    "print(\"Sampling some reverse trajectories\")\n",
    "samples, times = generate.generate_samples(\n",
    "    model, diffuser, t_limit=t_limit, return_all_times=True\n",
    ")\n",
    "samples, times = samples.cpu().numpy(), times.cpu().numpy()\n",
    "num_to_show = 4\n",
    "time_inds = np.arange(0, len(times), len(times) // num_to_show)\n",
    "time_inds[-1] = len(times) - 1\n",
    "for t_i in time_inds:\n",
    "    plot_mnist_digits(samples[t_i], grid_size=(10, 1), title=times[t_i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
